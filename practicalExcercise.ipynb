{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "textClassKernel",
      "language": "python",
      "name": "textclasskernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "practicalExcercise.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO4bHsXGdrfq",
        "outputId": "85779c5d-cbad-41bd-981c-07c75855e2a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "wO4bHsXGdrfq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "willing-output",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "71db7784-162b-4ccd-9271-fe80951d7b1b"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "%matplotlib inline\n",
        "\n",
        "data_paths = [f'drive/MyDrive/Data/refsa-sample-data/{x}/use_as_train_{x}.csv' for x in [\"ERIS\", \"Isoflavones\", \"Bacillus\"]]\n",
        "validation_paths =  [f'drive/MyDrive/Data/refsa-sample-data/{x}/use_as_validation_{x}.csv' for x in [\"ERIS\", \"Isoflavones\", \"Bacillus\"]]\n",
        "\n",
        "df = pd.read_csv(data_paths[0], index_col=0)\n",
        "df_test = pd.read_csv(validation_paths[0], index_col=0)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "id": "willing-output",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "(527, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X...Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Journal</th>\n",
              "      <th>Indicator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>O. Wessel, C. M. Olsen, E. Rimstad and M. K. D...</td>\n",
              "      <td>Piscine orthoreovirus (PRV) replicates in Atla...</td>\n",
              "      <td>Piscine orthoreovirus (PRV) is a reovirus that...</td>\n",
              "      <td>Vet Res</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>M. C. Hikke, C. Geertsema, V. Wu, S. W. Metz, ...</td>\n",
              "      <td>Alphavirus capsid proteins self-assemble into ...</td>\n",
              "      <td>The mosquito-borne chikungunya virus (CHIKV) c...</td>\n",
              "      <td>Biotechnol J</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>J. Nacher-Mestre, R. Serrano, E. Beltran, J. P...</td>\n",
              "      <td>Occurrence and potential transfer of mycotoxin...</td>\n",
              "      <td>Plant ingredients and processed animal protein...</td>\n",
              "      <td>Chemosphere</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>B. D. Johnson, S. L. Gilbert, B. Khan, D. L. C...</td>\n",
              "      <td>Cellular responses of eastern oysters, Crassos...</td>\n",
              "      <td>Because of the continued development and produ...</td>\n",
              "      <td>Mar Environ Res</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>L. Zi-qi, M. Qian, S. Feng-qing, W. Ying-wen, ...</td>\n",
              "      <td>Research progress of chitosan and its derivati...</td>\n",
              "      <td>Recently, the problem of heavy metal pollution...</td>\n",
              "      <td>Food &amp; Machinery</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            X...Author  ... Indicator\n",
              "377  O. Wessel, C. M. Olsen, E. Rimstad and M. K. D...  ...        -1\n",
              "172  M. C. Hikke, C. Geertsema, V. Wu, S. W. Metz, ...  ...        -1\n",
              "248  J. Nacher-Mestre, R. Serrano, E. Beltran, J. P...  ...         1\n",
              "525  B. D. Johnson, S. L. Gilbert, B. Khan, D. L. C...  ...         1\n",
              "614  L. Zi-qi, M. Qian, S. Feng-qing, W. Ying-wen, ...  ...        -1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "special-italian",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7aa0c3d-6591-4216-f71b-f104eda3035f"
      },
      "source": [
        "#check for null values\n",
        "df.isnull().sum()"
      ],
      "id": "special-italian",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X...Author    0\n",
              "Title         0\n",
              "Abstract      0\n",
              "Journal       1\n",
              "Indicator     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chemical-margin"
      },
      "source": [
        "X = df[[\"Title\", \"Abstract\"]].copy()\n",
        "y = df[\"Indicator\"]\n",
        "\n",
        "X_test = df_test[[\"Title\", \"Abstract\"]]\n",
        "y_test = df_test[\"Indicator\"]"
      ],
      "id": "chemical-margin",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regulated-romance"
      },
      "source": [
        "Cleaning text data\n",
        "===="
      ],
      "id": "regulated-romance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "literary-firmware",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839865b7-a120-4a03-f6c6-8709e489ff11"
      },
      "source": [
        "for abs in df[\"Abstract\"][:4]:\n",
        "    print(abs + \"\\n\")"
      ],
      "id": "literary-firmware",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Piscine orthoreovirus (PRV) is a reovirus that has predominantly been detected in Atlantic salmon (Salmo salar L.). PRV is associated with heart and skeletal muscle inflammation (HSMI) in farmed Atlantic salmon, and recently erythrocytes were identified as major target cells. The study of PRV replication and pathogenesis of the infection has been impeded by the inability to propagate PRV in vitro. In this study we developed an ex vivo cultivation system for PRV in Atlantic salmon erythrocytes. PRV was successfully passaged to naive erythrocytes using lysates of blood cells from infected salmon. During cultivation a significant increase in viral load was observed by RT-qPCR and flow cytometry, which coincided with the formation of cytoplasmic inclusions. The inclusions resembled viral factories and contained both PRV protein and dsRNA. In addition, the erythrocytes generated an antiviral immune gene activation after PRV infection, with significant up-regulation of IFN-alpha, RIG-I, Mx and PKR transcripts. Supernatants from the first passage successfully transmitted virus to naive erythrocytes. This study demonstrates that PRV replicates in Atlantic salmon erythrocytes ex vivo. The ex vivo infection model closely reflects the situation in vivo and can be used to study the infection and replication mechanisms of PRV, as well as the antiviral immune responses of salmonid erythrocytes.\n",
            "\n",
            "The mosquito-borne chikungunya virus (CHIKV) causes arthritic diseases in humans, whereas the aquatic salmonid alphavirus (SAV) is associated with high mortality in aquaculture of salmon and trout. Using modern biotechnological approaches, promising vaccine candidates based upon highly immunogenic, enveloped virus-like particles (eVLPs) have been developed. However, the eVLP structure (core, lipid membrane, surface glycoproteins) is more complex than that of non-enveloped, protein-only VLPs, which are structurally and morphologically 'simple'. In order to develop an alternative to alphavirus eVLPs, in this paper we engineered recombinant baculovirus vectors to produce high levels of alphavirus core-like particles (CLPs) in insect cells by expression of the CHIKV and SAV capsid proteins. The CLPs localize in dense nuclear bodies within the infected cell nucleus and are purified through a rapid and scalable protocol involving cell lysis, sonication and low-speed centrifugation steps. Furthermore, an immunogenic epitope from the alphavirus E2 glycoprotein can be successfully fused to the N-terminus of the capsid protein without disrupting the CLP self-assembling properties. We propose that immunogenic epitope-tagged alphavirus CLPs produced in insect cells present a simple and perhaps more stable alternative to alphavirus eVLPs.\n",
            "\n",
            "Plant ingredients and processed animal proteins (PAP) are suitable alternative feedstuffs for fish feeds in aquaculture practice, although their use can introduce contaminants that are not previously associated with marine salmon and gilthead sea bream farming. Mycotoxins are well known natural contaminants in plant feed material, although they also could be present on PAPs after fungi growth during storage. The present study surveyed commercially available plant ingredients (19) and PAP (19) for a wide range of mycotoxins (18) according to the EU regulations. PAP showed only minor levels of ochratoxin A and fumonisin B1 and the mycotoxin carry-over from feeds to fillets of farmed Atlantic salmon and gilthead sea bream (two main species of European aquaculture) was performed with plant ingredient based diets. Deoxynivalenol was the most prevalent mycotoxin in wheat, wheat gluten and corn gluten cereals with levels ranging from 17 to 814 and mug kg(-1), followed by fumonisins in corn products (range 11.1-4901 mug kg(-1) for fumonisin B1+B2+B3). Overall mycotoxin levels in fish feeds reflected the feed ingredient composition and the level of contaminant in each feed ingredient. In all cases the studied ingredients and feeds showed levels of mycotoxins below maximum residue limits established by the Commission Recommendation 2006/576/EC. Following these guidelines no mycotoxin carry-over was found from feeds to edible fillets of salmonids and a typically marine fish, such as gilthead sea bream. As far we know, this is the first report of mycotoxin surveillance in farmed fish species.\n",
            "\n",
            "Because of the continued development and production of a variety of nanomaterials and nanoparticles, their uptake and effects on the biota of marine ecosystems must be investigated. Filter feeding bivalve molluscs are highly adapted for capturing particles from the external environment and readily internalize nano- and micro-sized particles through endocytosis, so they are commonly used as valuable indicator species for nanoparticle studies. In these studies, adult eastern oysters, Crassostrea virginica, were exposed to a range of titanium dioxide nanoparticle (TiO2-NP) concentrations (5, 50, 500, and 5000 mug/L) in conjunction with natural sunlight. Isolated hepatopancreas tissues were also exposed to the same TiO2-NP concentrations using particles exposed to similar light and dark conditions. Dose-dependent decreases in lysosomal stability were observed in the adult oyster studies as well as in the isolated tissues, at exposures as low as 50 mug/L. Titanium accumulation in isolated hepatopancreas tissue studies was directly correlated to lysosomal destabilization. Based on measurements of lipid peroxidation as an indicator of oxidative stress, TiO2-NPs toxicity was not related to increased ROS production over the short-term course of these exposures. Analysis of particle size using dynamic light scattering (DLS) indicated that concentration had a significant impact on agglomeration rates, and the small agglomerates as well as individual particles are readily processed by oysters. Overall, this study illustrates that low concentrations of TiO2-NPs may cause sublethal toxicity on oysters, which might be enhanced under natural sunlight conditions. In estuarine environments, where these nanomaterials are likely to accumulate, agglomeration rates, interaction with organics, and responses to sunlight are critical in determining the extent of their bioreactivity and biological impacts.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nonprofit-carnival"
      },
      "source": [
        "Things to consider when cleaning the data:\n",
        "- abreviations\n",
        "- numeric values and citation numbers\n",
        "- hyphenated words like *mosquito-borne*\n",
        "\n",
        "There is probably no need to remove contractions due to scientific nature of the data. \n"
      ],
      "id": "nonprofit-carnival"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spectacular-mexican",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "614057b9-1de7-4d09-830f-42d744adf708"
      },
      "source": [
        "#tokenize and lowercase\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_and_lower(s):\n",
        "    return [x.lower() for x in word_tokenize(s)]\n",
        "\n",
        "X[\"tokenized_title\"] = X[\"Title\"].apply(tokenize_and_lower)\n",
        "X[\"tokenized_abstract\"] = X[\"Abstract\"].apply(tokenize_and_lower)\n",
        "X.head()"
      ],
      "id": "spectacular-mexican",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>tokenized_title</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>Piscine orthoreovirus (PRV) replicates in Atla...</td>\n",
              "      <td>Piscine orthoreovirus (PRV) is a reovirus that...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), replicates...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), is, a, reo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Alphavirus capsid proteins self-assemble into ...</td>\n",
              "      <td>The mosquito-borne chikungunya virus (CHIKV) c...</td>\n",
              "      <td>[alphavirus, capsid, proteins, self-assemble, ...</td>\n",
              "      <td>[the, mosquito-borne, chikungunya, virus, (, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>Occurrence and potential transfer of mycotoxin...</td>\n",
              "      <td>Plant ingredients and processed animal protein...</td>\n",
              "      <td>[occurrence, and, potential, transfer, of, myc...</td>\n",
              "      <td>[plant, ingredients, and, processed, animal, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Cellular responses of eastern oysters, Crassos...</td>\n",
              "      <td>Because of the continued development and produ...</td>\n",
              "      <td>[cellular, responses, of, eastern, oysters, ,,...</td>\n",
              "      <td>[because, of, the, continued, development, and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>Research progress of chitosan and its derivati...</td>\n",
              "      <td>Recently, the problem of heavy metal pollution...</td>\n",
              "      <td>[research, progress, of, chitosan, and, its, d...</td>\n",
              "      <td>[recently, ,, the, problem, of, heavy, metal, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  ...                                 tokenized_abstract\n",
              "377  Piscine orthoreovirus (PRV) replicates in Atla...  ...  [piscine, orthoreovirus, (, prv, ), is, a, reo...\n",
              "172  Alphavirus capsid proteins self-assemble into ...  ...  [the, mosquito-borne, chikungunya, virus, (, c...\n",
              "248  Occurrence and potential transfer of mycotoxin...  ...  [plant, ingredients, and, processed, animal, p...\n",
              "525  Cellular responses of eastern oysters, Crassos...  ...  [because, of, the, continued, development, and...\n",
              "614  Research progress of chitosan and its derivati...  ...  [recently, ,, the, problem, of, heavy, metal, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liquid-outdoors",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ccf274-9b7e-4904-954e-5387d8ac586c"
      },
      "source": [
        "#remove punctuation and stopwords\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "chars_for_removal = set(list(string.punctuation) + stopwords.words(\"english\"))\n",
        "print(chars_for_removal)"
      ],
      "id": "liquid-outdoors",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "{']', '`', 'aren', 'yourselves', 'it', 'about', 'didn', 'll', \"that'll\", 'how', '(', 'ma', 'by', 'both', 'yours', 'you', ')', 'doing', 'then', 'weren', 'isn', 'have', 'only', 're', 'herself', \"didn't\", ':', 'some', 'in', '%', 'm', 'whom', 'more', 'if', '^', 'while', 'its', '*', 'your', 'the', \"wouldn't\", 'hers', 'down', 'or', \"shan't\", '\\\\', 'being', 'few', '<', 'ourselves', \"she's\", 'don', 'haven', 'them', 'there', 'we', 'for', 'over', '#', '@', \"you've\", 'himself', 'between', 'i', 'such', 'own', 'o', '{', 'had', 'a', 'ain', '|', 'now', 't', 'nor', 'am', \"you're\", 'this', \"hadn't\", 'than', 'which', 'shan', 'out', 'so', 'off', \"doesn't\", 'do', 'each', 'wasn', 'myself', 'her', \"it's\", 'did', 'above', \"don't\", 'y', 'hadn', 'mustn', \"hasn't\", '_', 'couldn', 'below', 'he', \"you'd\", 'been', 'again', 'their', 'needn', 'she', 'was', 'here', 'other', 'theirs', 'until', 'will', 'on', 'is', \"aren't\", '$', 'up', 'me', 'with', \"couldn't\", 'at', 'but', 'd', 'are', 'all', 's', '&', 'doesn', \"won't\", 'why', \"needn't\", '\"', \"you'll\", 'itself', 'these', 'to', \"should've\", ';', 'where', '[', 'against', 'not', 'any', 'into', 'from', 'his', 'and', \"'\", 'before', 'too', '?', 'hasn', 'no', 'mightn', 'of', \"haven't\", 'through', \"weren't\", 'under', 'him', 'when', \"mustn't\", 'shouldn', \"isn't\", 'those', 'should', '+', 'after', 'once', 'wouldn', '!', 'very', 'because', '>', 'be', ',', 'were', 'has', 'during', 'having', 'can', 'further', 'ours', 'they', 'themselves', '/', 'yourself', \"mightn't\", \"shouldn't\", 'an', 'who', 'most', '.', 'our', 'my', 'just', 'as', 'that', '}', 've', '~', '-', \"wasn't\", '=', 'same', 'what', 'does', 'won'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "experienced-copying",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "766fd227-90a8-4d8f-92fd-6e831962ef4e"
      },
      "source": [
        "def filter_words(string_list):\n",
        "    return [word for word in string_list if word not in chars_for_removal]\n",
        "\n",
        "X[\"filtered_title\"] = X[\"tokenized_title\"].apply(filter_words)\n",
        "X[\"filtered_abstract\"] = X[\"tokenized_abstract\"].apply(filter_words)\n",
        "X.head()"
      ],
      "id": "experienced-copying",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>tokenized_title</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>filtered_title</th>\n",
              "      <th>filtered_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>Piscine orthoreovirus (PRV) replicates in Atla...</td>\n",
              "      <td>Piscine orthoreovirus (PRV) is a reovirus that...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), replicates...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), is, a, reo...</td>\n",
              "      <td>[piscine, orthoreovirus, prv, replicates, atla...</td>\n",
              "      <td>[piscine, orthoreovirus, prv, reovirus, predom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Alphavirus capsid proteins self-assemble into ...</td>\n",
              "      <td>The mosquito-borne chikungunya virus (CHIKV) c...</td>\n",
              "      <td>[alphavirus, capsid, proteins, self-assemble, ...</td>\n",
              "      <td>[the, mosquito-borne, chikungunya, virus, (, c...</td>\n",
              "      <td>[alphavirus, capsid, proteins, self-assemble, ...</td>\n",
              "      <td>[mosquito-borne, chikungunya, virus, chikv, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>Occurrence and potential transfer of mycotoxin...</td>\n",
              "      <td>Plant ingredients and processed animal protein...</td>\n",
              "      <td>[occurrence, and, potential, transfer, of, myc...</td>\n",
              "      <td>[plant, ingredients, and, processed, animal, p...</td>\n",
              "      <td>[occurrence, potential, transfer, mycotoxins, ...</td>\n",
              "      <td>[plant, ingredients, processed, animal, protei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Cellular responses of eastern oysters, Crassos...</td>\n",
              "      <td>Because of the continued development and produ...</td>\n",
              "      <td>[cellular, responses, of, eastern, oysters, ,,...</td>\n",
              "      <td>[because, of, the, continued, development, and...</td>\n",
              "      <td>[cellular, responses, eastern, oysters, crasso...</td>\n",
              "      <td>[continued, development, production, variety, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>Research progress of chitosan and its derivati...</td>\n",
              "      <td>Recently, the problem of heavy metal pollution...</td>\n",
              "      <td>[research, progress, of, chitosan, and, its, d...</td>\n",
              "      <td>[recently, ,, the, problem, of, heavy, metal, ...</td>\n",
              "      <td>[research, progress, chitosan, derivatives, re...</td>\n",
              "      <td>[recently, problem, heavy, metal, pollution, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  ...                                  filtered_abstract\n",
              "377  Piscine orthoreovirus (PRV) replicates in Atla...  ...  [piscine, orthoreovirus, prv, reovirus, predom...\n",
              "172  Alphavirus capsid proteins self-assemble into ...  ...  [mosquito-borne, chikungunya, virus, chikv, ca...\n",
              "248  Occurrence and potential transfer of mycotoxin...  ...  [plant, ingredients, processed, animal, protei...\n",
              "525  Cellular responses of eastern oysters, Crassos...  ...  [continued, development, production, variety, ...\n",
              "614  Research progress of chitosan and its derivati...  ...  [recently, problem, heavy, metal, pollution, a...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "similar-roulette"
      },
      "source": [
        "Im not sure whether stemming the data would be a good choice - will domain-specific words get well lematized?\n",
        "\n"
      ],
      "id": "similar-roulette"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brief-raising",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "b9940d8c-b6e6-4e35-cd83-50a29160f15b"
      },
      "source": [
        "#adding pos tags for lemmatization with wordnet\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "X[\"pos_title\"] = X[\"filtered_title\"].apply(nltk.tag.pos_tag)\n",
        "X[\"pos_abstract\"] = X[\"filtered_abstract\"].apply(nltk.tag.pos_tag)\n",
        "\n",
        "def map_to_wordnet_pos(tuple_list):\n",
        "    return [(word, get_wnet_tag(tag)) for (word, tag) in tuple_list]\n",
        " \n",
        "def get_wnet_tag(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    if tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    if tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "    \n",
        "X[\"wntag_title\"] = X[\"pos_title\"].apply(map_to_wordnet_pos)\n",
        "X[\"wntag_abstract\"] = X[\"pos_abstract\"].apply(map_to_wordnet_pos)    \n",
        "\n",
        "X.head()\n"
      ],
      "id": "brief-raising",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>tokenized_title</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>filtered_title</th>\n",
              "      <th>filtered_abstract</th>\n",
              "      <th>pos_title</th>\n",
              "      <th>pos_abstract</th>\n",
              "      <th>wntag_title</th>\n",
              "      <th>wntag_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>Piscine orthoreovirus (PRV) replicates in Atla...</td>\n",
              "      <td>Piscine orthoreovirus (PRV) is a reovirus that...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), replicates...</td>\n",
              "      <td>[piscine, orthoreovirus, (, prv, ), is, a, reo...</td>\n",
              "      <td>[piscine, orthoreovirus, prv, replicates, atla...</td>\n",
              "      <td>[piscine, orthoreovirus, prv, reovirus, predom...</td>\n",
              "      <td>[(piscine, NN), (orthoreovirus, NN), (prv, NN)...</td>\n",
              "      <td>[(piscine, NN), (orthoreovirus, NN), (prv, NN)...</td>\n",
              "      <td>[(piscine, n), (orthoreovirus, n), (prv, n), (...</td>\n",
              "      <td>[(piscine, n), (orthoreovirus, n), (prv, n), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Alphavirus capsid proteins self-assemble into ...</td>\n",
              "      <td>The mosquito-borne chikungunya virus (CHIKV) c...</td>\n",
              "      <td>[alphavirus, capsid, proteins, self-assemble, ...</td>\n",
              "      <td>[the, mosquito-borne, chikungunya, virus, (, c...</td>\n",
              "      <td>[alphavirus, capsid, proteins, self-assemble, ...</td>\n",
              "      <td>[mosquito-borne, chikungunya, virus, chikv, ca...</td>\n",
              "      <td>[(alphavirus, NN), (capsid, NN), (proteins, VB...</td>\n",
              "      <td>[(mosquito-borne, JJ), (chikungunya, NN), (vir...</td>\n",
              "      <td>[(alphavirus, n), (capsid, n), (proteins, v), ...</td>\n",
              "      <td>[(mosquito-borne, a), (chikungunya, n), (virus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>Occurrence and potential transfer of mycotoxin...</td>\n",
              "      <td>Plant ingredients and processed animal protein...</td>\n",
              "      <td>[occurrence, and, potential, transfer, of, myc...</td>\n",
              "      <td>[plant, ingredients, and, processed, animal, p...</td>\n",
              "      <td>[occurrence, potential, transfer, mycotoxins, ...</td>\n",
              "      <td>[plant, ingredients, processed, animal, protei...</td>\n",
              "      <td>[(occurrence, NN), (potential, NN), (transfer,...</td>\n",
              "      <td>[(plant, NN), (ingredients, NNS), (processed, ...</td>\n",
              "      <td>[(occurrence, n), (potential, n), (transfer, n...</td>\n",
              "      <td>[(plant, n), (ingredients, n), (processed, v),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Cellular responses of eastern oysters, Crassos...</td>\n",
              "      <td>Because of the continued development and produ...</td>\n",
              "      <td>[cellular, responses, of, eastern, oysters, ,,...</td>\n",
              "      <td>[because, of, the, continued, development, and...</td>\n",
              "      <td>[cellular, responses, eastern, oysters, crasso...</td>\n",
              "      <td>[continued, development, production, variety, ...</td>\n",
              "      <td>[(cellular, JJ), (responses, NNS), (eastern, J...</td>\n",
              "      <td>[(continued, JJ), (development, NN), (producti...</td>\n",
              "      <td>[(cellular, a), (responses, n), (eastern, a), ...</td>\n",
              "      <td>[(continued, a), (development, n), (production...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>Research progress of chitosan and its derivati...</td>\n",
              "      <td>Recently, the problem of heavy metal pollution...</td>\n",
              "      <td>[research, progress, of, chitosan, and, its, d...</td>\n",
              "      <td>[recently, ,, the, problem, of, heavy, metal, ...</td>\n",
              "      <td>[research, progress, chitosan, derivatives, re...</td>\n",
              "      <td>[recently, problem, heavy, metal, pollution, a...</td>\n",
              "      <td>[(research, NN), (progress, NN), (chitosan, JJ...</td>\n",
              "      <td>[(recently, RB), (problem, NN), (heavy, JJ), (...</td>\n",
              "      <td>[(research, n), (progress, n), (chitosan, a), ...</td>\n",
              "      <td>[(recently, r), (problem, n), (heavy, a), (met...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Title  ...                                     wntag_abstract\n",
              "377  Piscine orthoreovirus (PRV) replicates in Atla...  ...  [(piscine, n), (orthoreovirus, n), (prv, n), (...\n",
              "172  Alphavirus capsid proteins self-assemble into ...  ...  [(mosquito-borne, a), (chikungunya, n), (virus...\n",
              "248  Occurrence and potential transfer of mycotoxin...  ...  [(plant, n), (ingredients, n), (processed, v),...\n",
              "525  Cellular responses of eastern oysters, Crassos...  ...  [(continued, a), (development, n), (production...\n",
              "614  Research progress of chitosan and its derivati...  ...  [(recently, r), (problem, n), (heavy, a), (met...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "considered-magic"
      },
      "source": [
        "#lemmatize with wordnet\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(tuple_list):\n",
        "    return [lemmatizer.lemmatize(word, tag) for (word, tag) in tuple_list]\n",
        "\n",
        "X[\"lem_title\"] = X[\"wntag_title\"].apply(lemmatize)\n",
        "X[\"lem_abstract\"] = X[\"wntag_abstract\"].apply(lemmatize)\n",
        "\n",
        "cleaned_text = pd.DataFrame(data=X[[\"lem_title\", \"lem_abstract\"]], index = X.index)\n",
        "cleaned_text = cleaned_text.rename(columns={\"lem_title\":\"title\", \"lem_abstract\": \"abstract\"})"
      ],
      "id": "considered-magic",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unsigned-headline"
      },
      "source": [
        "Exploratory Data Analysis\n",
        "==="
      ],
      "id": "unsigned-headline"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "missing-cradle"
      },
      "source": [
        ""
      ],
      "id": "missing-cradle",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "domestic-motion"
      },
      "source": [
        ""
      ],
      "id": "domestic-motion",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expressed-channel"
      },
      "source": [
        ""
      ],
      "id": "expressed-channel",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undefined-interstate"
      },
      "source": [
        "Classification\n",
        "===\n"
      ],
      "id": "undefined-interstate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broke-helping",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e427405d-c5d3-4e27-dd8e-a1cc6d52c047"
      },
      "source": [
        "#baseline classifier - always return majority class\n",
        "class BaselineClassifier:\n",
        "    def __init__(self):\n",
        "        self.majority_class = np.NaN\n",
        "        \n",
        "    def fit(self, x, y):\n",
        "        self.majority_class = y.value_counts()[:1].index.to_list()[0]\n",
        "        return\n",
        "    def predict(self, x):\n",
        "        return pd.Series(np.ones((x.shape[0],)) * self.majority_class, index = x.index)\n",
        "    \n",
        "    def score(self, x, y):\n",
        "        p = self.predict(x)\n",
        "        comp = y==p\n",
        "        return len(comp[comp==True])/len(comp)\n",
        "        \n",
        "        \n",
        "clf = BaselineClassifier()\n",
        "clf.fit(X,y)\n",
        "pred = clf.predict(X_test)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(f'Baseline classifier\\'s accuracy (always returns majority class): {score}')"
      ],
      "id": "broke-helping",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline classifier's accuracy (always returns majority class): 0.8484848484848485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dominican-confidence"
      },
      "source": [
        "**Baseline classifier** achieves accuracy that is pretty impresive at a glance - 84,84% of examples are corretly classifies which corresponds with the expectations. "
      ],
      "id": "dominican-confidence"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "geological-suggestion",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "e2a29dbc-387d-4651-9ea1-770484927221"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#preprocess train data\n",
        "vectorizerAb = CountVectorizer()\n",
        "vectorizerTit = CountVectorizer()\n",
        "\n",
        "preprocessedAbstract = vectorizerAb.fit_transform(cleaned_text[\"abstract\"].values)\n",
        "abstracts = pd.DataFrame(data=preprocessedAbstract.toarray(), index=cleaned_text.index)\n",
        "\n",
        "preprocessedTitle = vectorizerTit.fit_transform(cleaned_text[\"Title\"].values)\n",
        "titles = pd.DataFrame(data=preprocessedTitle.toarray(), index=cleaned_text.index)\n",
        "\n",
        "x_train = pd.concat([abstracts, titles], axis=1)\n",
        "print(x_train.shape, y.shape, titles.shape, abstracts.shape)"
      ],
      "id": "geological-suggestion",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6d80b3d54071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvectorizerTit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpreprocessedAbstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizerAb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abstract\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mabstracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessedAbstract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "structured-fiction"
      },
      "source": [
        "#preprocess test data\n",
        "abstracts_test = vectorizerAb.transform(X_test[\"Abstract\"].values)\n",
        "titles_test = vectorizerTit.transform(X_test[\"Title\"].values)\n",
        "\n",
        "prep_ab = pd.DataFrame(data=abstracts_test.toarray(), index = X_test.index)\n",
        "prep_tit = pd.DataFrame(data=titles_test.toarray(), index=X_test.index)\n",
        "\n",
        "x_test = pd.concat([prep_ab, prep_tit],axis=1)\n",
        "print(x_test.shape, prep_tit.shape, prep_ab.shape)"
      ],
      "id": "structured-fiction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "manufactured-binary"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "scores = {}\n",
        "\n",
        "clf = LogisticRegressionCV()\n",
        "clf.fit(x_train, y)\n",
        "score = clf.score(x_test, y_test)\n",
        "print(f'Accuracy for Logistic Regression Classifier with CountVectorization - {score}')"
      ],
      "id": "manufactured-binary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imported-affair"
      },
      "source": [
        "The result might seem impressive at a glance, but when we look at the accuracy of baseline classifier we can see that logistic regression classifier did not bring anything new to the table, its only as good as not looking at the data at all and then guessing majority class. "
      ],
      "id": "imported-affair"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "functioning-clothing"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(x_train, y)\n",
        "score = clf.score(x_test, y_test)\n",
        "print(f'Accuracy for SupportVectorClassifier with CountVectorization - {score}')"
      ],
      "id": "functioning-clothing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strong-employment"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x_train, y)\n",
        "score = clf.score(x_test, y_test)\n",
        "print(f'Accuracy for DecisionTreeClassifier with CountVectorization - {score}')\n",
        "\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x_train, y)\n",
        "score = clf.score(x_test, y_test)\n",
        "print(f'Accuracy for RandomForestClassifier with CountVectorization - {score}')\n",
        "\n",
        "\n",
        "\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(x_train, y)\n",
        "score = clf.score(x_test, y_test)\n",
        "print(f'Accuracy for Tree-based AdaBoost with CountVectorization - {score}')"
      ],
      "id": "strong-employment",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "creative-discipline"
      },
      "source": [
        ""
      ],
      "id": "creative-discipline",
      "execution_count": null,
      "outputs": []
    }
  ]
}