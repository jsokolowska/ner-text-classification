{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "import pandas as pd\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "from src.representations import DoubleTfIdfVectorizer, SpacyNEClassifier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IN] Tokens:['Rick', 'Morris', 'is', 'a', 'winner', '.'] Tags: ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n",
      "[OUT] Tokens:['rick', 'morris', 'is', 'a', 'winner', '.'] Tags: ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n",
      "[IN] Tokens:['He', 'is', 'the', 'UK', 'Independence', 'Party', \"'s\", 'weapon', '.'] Tags: ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O']\n",
      "[OUT] Tokens:['he', 'is', 'the', 'uk', 'independence', 'party', \"'s\", 'weapon', '.'] Tags: ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O']\n",
      "[IN] Tokens:['Rick', 'Morris', 'is', 'a', 'winner', '.'] Tags: ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n",
      "[OUT] Tokens:['rick', 'morris', 'is', 'a', 'winner', '.'] Tags: ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n",
      "Terms: ['rick', 'PERSON', 'morris', 'PERSON', 'is', 'a', 'winner', '.']\n",
      "Feature counts: {'rick': 1, 'PERSON': 2, 'morris': 1, 'is': 2, 'a': 1, 'winner': 1, '.': 2, 'he': 1, 'the': 1, 'uk': 1, 'GPE': 1, 'independence': 1, 'party': 1, \"'s\": 1, 'weapon': 1}\n",
      "[IN] Tokens:['He', 'is', 'the', 'UK', 'Independence', 'Party', \"'s\", 'weapon', '.'] Tags: ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O']\n",
      "[OUT] Tokens:['he', 'is', 'the', 'uk', 'independence', 'party', \"'s\", 'weapon', '.'] Tags: ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O']\n",
      "Terms: ['he', 'is', 'the', 'uk', 'GPE', 'independence', 'NORP', 'party', 'NORP', \"'s\", 'NORP', 'weapon', '.']\n",
      "Feature counts: {'rick': 1, 'PERSON': 2, 'morris': 1, 'is': 2, 'a': 1, 'winner': 1, '.': 2, 'he': 1, 'the': 1, 'uk': 1, 'GPE': 1, 'independence': 1, 'party': 1, \"'s\": 1, 'weapon': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vocab, row ['Rick', 'Morris', 'is', 'a', 'winner', '.'], tokens: ['rick', 'morris', 'is', 'a', 'winner', '.']\n",
      "Count vocab, row ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O'], tags: ['B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O']\n",
      "Count vocab, keys: ['rick', 'PERSON', 'morris', 'PERSON', 'is', 'a', 'winner', '.']\n",
      "Count vocab, row ['He', 'is', 'the', 'UK', 'Independence', 'Party', \"'s\", 'weapon', '.'], tokens: ['he', 'is', 'the', 'uk', 'independence', 'party', \"'s\", 'weapon', '.']\n",
      "Count vocab, row ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O'], tags: ['O', 'O', 'O', 'B-GPE', 'B-NORP', 'I-NORP', 'I-NORP', 'O', 'O']\n",
      "Count vocab, keys: ['he', 'is', 'the', 'uk', 'GPE', 'independence', 'NORP', 'party', 'NORP', \"'s\", 'NORP', 'weapon', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2, 15)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.representations import DoubleTfIdfVectorizer, SpacyNEClassifier,BioTfIdfVectorizer\n",
    "import pandas as pd\n",
    "t3 = \"He has worked in Mexico and Uruguay.\"\n",
    "t4 = \"He is the UK Independence Party's weapon\"\n",
    "t2 = \"Rick Morris is a winner.\"\n",
    "t1 = \"UKIP's secret weapon?\"\n",
    "texts = [t2, t4]\n",
    "docs = [\n",
    "    [\"Rick\", \"Morris\", \"is\", \"a\",  \"winner\",\".\"],\n",
    "    [\"He\",\"is\",\"the\",\"UK\",\"Independence\",\"Party\",\"'s\",\"weapon\",\".\"]\n",
    "]\n",
    "tags = [\n",
    "    [\"B-PERSON\", \"I-PERSON\", \"O\", \"O\",  \"O\",\"O\"],\n",
    "    [\"O\",\"O\",\"O\",\"B-GPE\",\"B-NORP\",\"I-NORP\",\"I-NORP\",\"O\",\"O\"]\n",
    "]\n",
    "ner = SpacyNEClassifier()\n",
    "vect = BioTfIdfVectorizer(ner,\n",
    "            filter_stopwords = False,\n",
    "            filter_punctuation=False,\n",
    "            lemmatize = False,\n",
    "            normalize = False,\n",
    "            fix_contractions = False)\n",
    "\n",
    "df = pd.DataFrame(vect.fit_transform(tokenized=pd.Series(docs), bio_tags= pd.Series(tags)).toarray(), columns = vect.get_feature_names())\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"'s\",\n '.',\n 'GPE',\n 'PERSON',\n 'a',\n 'he',\n 'independence',\n 'is',\n 'morris',\n 'party',\n 'rick',\n 'the',\n 'uk',\n 'weapon',\n 'winner']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c  = vect.get_feature_names()\n",
    "c.sort()\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!h] \\label{tab:tfidf-bio} \\centering\n",
      "\\caption{Reprezentacja wektorowa bio}\\begin{tabular}{| c | c | c |}\\hline \n",
      "Tokeny & Dokument 1 & Dokument 2\\\\ \\hline \n",
      "PERSON&0.333 & 0.000 \\\\ \\hline\n",
      "rick&0.119 & 0.000 \\\\ \\hline\n",
      "morris&0.119 & 0.000 \\\\ \\hline\n",
      "is&0.167 & 0.111 \\\\ \\hline\n",
      "a&0.119 & 0.000 \\\\ \\hline\n",
      "winner&0.119 & 0.000 \\\\ \\hline\n",
      ".&0.167 & 0.111 \\\\ \\hline\n",
      "he&0.000 & 0.079 \\\\ \\hline\n",
      "the&0.000 & 0.079 \\\\ \\hline\n",
      "uk&0.000 & 0.079 \\\\ \\hline\n",
      "GPE&0.000 & 0.079 \\\\ \\hline\n",
      "independence&0.000 & 0.079 \\\\ \\hline\n",
      "party&0.000 & 0.079 \\\\ \\hline\n",
      "'s&0.000 & 0.079 \\\\ \\hline\n",
      "weapon&0.000 & 0.079 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def df_to_latex (df: pd.DataFrame, label:str, caption):\n",
    "    latex = \"\\\\begin{table}[!h] \\label{\" +label+ \"} \\centering\\n\" \\\n",
    "            \"\\caption{\" + caption + \"}\" \\\n",
    "            \"\\\\begin{tabular}{\"\n",
    "    headers = ['Dokument 1','Dokument 2']\n",
    "    latex += '| c ' * (len(headers) + 1)\n",
    "    latex += '|}\\hline \\n'\n",
    "    latex += \"Tokeny & \" + \" & \".join(headers)  + \"\\\\\\\\ \\hline \\n\"\n",
    "\n",
    "    for col in df.columns:\n",
    "        latex += col + \"&\"\n",
    "        for h_idx in range(len(headers)):\n",
    "            latex +=  \"{0:.3f}\".format(df.iloc[h_idx].loc[col]) + \" & \"\n",
    "        latex = latex[:-2]  #delete last &\n",
    "        latex += \"\\\\\\\\ \\hline\\n\"\n",
    "\n",
    "    latex += \"\\end{tabular}\\n\\end{table}\\n\"\n",
    "    return latex\n",
    "\n",
    "print(df_to_latex(df, \"tab:tfidf-bio\",\"Reprezentacja wektorowa bio\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!h] \\label{tab:tfidf-bio} \\centering\n",
      "\\caption{Reprezentacja wektorowa bio}\\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c |}\\hline \n",
      "Zbiór danych & PERSON & rick & morris & is & a & winner & he & the & uk & independence & party & weapon\\\\ \\hline \n",
      "0 & 0.33 & 0.12 & 0.12 & 0.17 & 0.12 & 0.12 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 \\\\ \\hline\n",
      "1 & 0.00 & 0.00 & 0.00 & 0.12 & 0.00 & 0.00 & 0.09 & 0.09 & 0.09 & 0.09 & 0.09 & 0.09 \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def df_to_latex_old (df: pd.DataFrame, label:str, caption):\n",
    "    latex = \"\\\\begin{table}[!h] \\label{\" +label+ \"} \\centering\\n\" \\\n",
    "            \"\\caption{\" + caption + \"}\" \\\n",
    "            \"\\\\begin{tabular}{\"\n",
    "    cols = df.columns.tolist()\n",
    "    latex += '| c ' * (len(cols) + 1)\n",
    "    latex += '|}\\hline \\n'\n",
    "    latex += \"Zbiór danych & \" + \" & \".join(cols)  + \"\\\\\\\\ \\hline \\n\"\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        latex += str(index) + \" & \"\n",
    "        for c in cols:\n",
    "            latex +=  \"{0:.2f}\".format(row[c]) + \" & \"\n",
    "        latex = latex[:-2]  #delete last &\n",
    "        latex += \"\\\\\\\\ \\hline\\n\"\n",
    "\n",
    "    latex += \"\\end{tabular}\\n\\end{table}\\n\"\n",
    "    return latex\n",
    "print(df_to_latex_old(df, \"tab:tfidf-bio\",\"Reprezentacja wektorowa bio\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def load_raw(data: Dataset, name):\n",
    "    return pd.read_csv(DATA_DIR + data.value + \"\\\\raw\\\\\" + name + \".csv\", nrows = 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ner = SpacyNEClassifier()\n",
    "double_vect = DoubleTfIdfVectorizer(ner_clf=ner, min_df=1,\n",
    "        max_df=20)\n",
    "df = load_raw(Dataset.BBC, \"train\")\n",
    "\n",
    "res = double_vect.fit_transform(df['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "save_npz(DATA_DIR + \"npz-try.npz\", res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "columns_df = pd.DataFrame({'col': double_vect.get_feature_names()})\n",
    "columns_df.to_csv(DATA_DIR+ \"npz-column.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def save_as_npz (dataset: Dataset, state: State, name, vectorizer, df_raw: pd.DataFrame, sp_array):\n",
    "    save_npz(DATA_DIR + dataset.value + \"\\\\\" + state.value + \"\\\\\" + \"array-\" + name + \".npz\", sp_array)\n",
    "    df_raw[\"target\"].to_csv(DATA_DIR + dataset.value + \"\\\\\" + state.value + \"\\\\\" + \"target-\" + name + \".csv\", index=False)\n",
    "    validate_or_save_columns(dataset, state, vectorizer)\n",
    "\n",
    "def validate_or_save_columns (dataset: Dataset, state: State, vectorizer):\n",
    "    name = DATA_DIR + dataset.value + \"\\\\\" + state.value + \"\\\\columns.csv\"\n",
    "    col_df = pd.DataFrame({\"columns\": vectorizer.get_feature_names()})\n",
    "    if os.path.exists(name):\n",
    "        cols = pd.read_csv(name)\n",
    "        assert cols.shape == col_df.shape\n",
    "    else:\n",
    "        col_df.to_csv(name, index = False)\n",
    "\n",
    "def read_as_dataframe(dataset: Dataset, state: State, name):\n",
    "    data_dir = DATA_DIR + dataset.value + \"\\\\\" + state.value + \"\\\\\"\n",
    "    sp_array = load_npz(data_dir + \"array-\" + name + \".npz\" )\n",
    "    cols = pd.read_csv(data_dir + \"columns.csv\")\n",
    "    target = pd.read_csv(data_dir +  \"target-\" + name + \".csv\")\n",
    "\n",
    "    # sanity check\n",
    "    assert len(cols) == sp_array.shape[1]\n",
    "    assert len(target) == sp_array.shape[0]\n",
    "    df = pd.DataFrame(sp_array.toarray(), columns=cols['columns'])\n",
    "    df['TARGET'] = target['target']\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "save_as_npz(Dataset.AG_NEWS, State.BIO, \"test-save-npz\",double_vect, df, res)\n",
    "read_as_dataframe(Dataset.AG_NEWS, State.BIO, \"test-save-npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "columns     offer     video    demand   service  programme        tv  \\\n0       -0.069626 -0.078256 -0.071983 -0.052171  -0.057441 -0.069316   \n1        0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n2        0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n3        0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n4       -0.006573  0.000000  0.000000  0.000000   0.000000  0.000000   \n\ncolumns    sky_NE  telewest_NE    pvr_NE     cable  ...  dispute  radio_NE  \\\n0       -0.067801    -0.067801 -0.067801 -0.067501  ...      0.0       0.0   \n1        0.000000     0.000000  0.000000  0.000000  ...      0.0       0.0   \n2        0.000000     0.000000  0.000000  0.000000  ...      0.0       0.0   \n3        0.000000     0.000000  0.000000  0.000000  ...      0.0       0.0   \n4        0.000000     0.000000  0.000000  0.000000  ...      0.0       0.0   \n\ncolumns  spectator  butt  bigley_NE  edit  yes  angry  semitic_NE  \\\n0              0.0   0.0        0.0   0.0  0.0    0.0         0.0   \n1              0.0   0.0        0.0   0.0  0.0    0.0         0.0   \n2              0.0   0.0        0.0   0.0  0.0    0.0         0.0   \n3              0.0   0.0        0.0   0.0  0.0    0.0         0.0   \n4              0.0   0.0        0.0   0.0  0.0    0.0         0.0   \n\ncolumns         TARGET  \n0                 tech  \n1             politics  \n2                sport  \n3                 tech  \n4        entertainment  \n\n[5 rows x 2027 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>columns</th>\n      <th>offer</th>\n      <th>video</th>\n      <th>demand</th>\n      <th>service</th>\n      <th>programme</th>\n      <th>tv</th>\n      <th>sky_NE</th>\n      <th>telewest_NE</th>\n      <th>pvr_NE</th>\n      <th>cable</th>\n      <th>...</th>\n      <th>dispute</th>\n      <th>radio_NE</th>\n      <th>spectator</th>\n      <th>butt</th>\n      <th>bigley_NE</th>\n      <th>edit</th>\n      <th>yes</th>\n      <th>angry</th>\n      <th>semitic_NE</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.069626</td>\n      <td>-0.078256</td>\n      <td>-0.071983</td>\n      <td>-0.052171</td>\n      <td>-0.057441</td>\n      <td>-0.069316</td>\n      <td>-0.067801</td>\n      <td>-0.067801</td>\n      <td>-0.067801</td>\n      <td>-0.067501</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>politics</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.006573</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>entertainment</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2027 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = read_as_dataframe(Dataset.AG_NEWS, State.BIO, \"test-save-npz\")\n",
    "\n",
    "print(df2.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['offer', 'video', 'demand', 'service', 'programme', 'tv', 'sky_NE',\n       'telewest_NE', 'pvr_NE', 'cable',\n       ...\n       'dispute', 'radio_NE', 'spectator', 'butt', 'bigley_NE', 'edit', 'yes',\n       'angry', 'semitic_NE', 'TARGET'],\n      dtype='object', name='columns', length=2027)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "38"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}